import { useCredit } from "@/features/payment/context/CreditContext";
import { BillingService } from "@/features/payment/services/BillingService";
import { VideoApiService } from "../../../../app/internal/video/services/falService";
import { useToast } from "@/hooks/use-toast";
import { useState, useEffect, useCallback } from "react";
import { useRouter } from "next/navigation";
import { ReadonlyURLSearchParams } from "next/navigation";
import { useWebSocket } from '@/hooks/useWebSocket';
import { useAuth } from "@/features/user/AuthContext";
import { AspectRatioType, ResolutionType, DurationType } from '../types/modelSettingTypes';
import { GenerationNotificationService } from '@/features/admin/services/GenerationNotificationService';
import { useVideoWebSocket } from "@/app/providers";

interface VideoGenerationData {
  prompt: string;
  aspectRatio: string;
  duration: string;
  quality?: string;
  style?: string;
  endpoint: string;
  imageFile?: File | null;
  fileUrl?: string;
  upscaling?: boolean;
  cameraControl?: string;
  seed?: number;
  resolution?: string;
  numFrames?: number;
  negative_prompt?: string;
  cfg_scale?: number;
  autoSelectNotificationId?: number;
}

interface FileItem {
  fileUrl: string;
  name: string;
}

interface UseVideoGenerationProps {
  searchParams?: ReadonlyURLSearchParams | null;
}

export default function useVideoGeneration({ searchParams }: UseVideoGenerationProps = {}) {
  const { updateCredits } = useCredit();
  const router = useRouter();
  const { id: userId } = useAuth();
  
  // ì˜ìƒ ìƒì„±ìš© WebSocket ì—°ê²°
  const { connectForVideoGeneration, isConnected } = useVideoWebSocket();

  // ì˜ìƒ ìƒì„± ë° ì €ì¥ ê´€ë ¨ ìƒíƒœ
  const [videoUrl, setVideoUrl] = useState("");
  const [errorMessage, setErrorMessage] = useState("");
  const [isUpscaling, setIsUpscaling] = useState(false);
  const [upscaledVideoUrl, setUpscaledVideoUrl] = useState("");

  // ì‚¬ì´ë“œë°” ë° í´ë” ê´€ë ¨ ìƒíƒœ
  const [activeTab, setActiveTab] = useState<"video" | "image" | "text">("image");
  const [selectedEndpoint, setSelectedEndpoint] = useState("luna");
  const [quality, setQuality] = useState<"standard" | "high">("standard");
  const [style, setStyle] = useState<"realistic" | "creative">("realistic");

  // ì°¸ì¡° ì´ë¯¸ì§€ ë° í”„ë¡¬í”„íŠ¸ ê´€ë ¨ ìƒíƒœ
  const [referenceImageFile, setReferenceImageFile] = useState<File | null>(null);
  const [referenceImageUrl, setReferenceImageUrl] = useState("");
  const [referencePrompt, setReferencePrompt] = useState("");
  const [referenceModel, setReferenceModel] = useState("");

  const { toast } = useToast();

  // URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì²˜ë¦¬
  useEffect(() => {
    if (searchParams) {
      const prompt = searchParams.get("prompt");
      const imageUrl = searchParams.get("imageUrl");
      const model = searchParams.get("model");

      if (prompt) setReferencePrompt(prompt);
      if (imageUrl) setReferenceImageUrl(imageUrl);
      if (model) {
        setReferenceModel(model);
        setSelectedEndpoint(model);
      }
    }
  }, [searchParams]);

  // VideoSidebarì—ì„œ ì „ë‹¬ë°›ì€ ë°ì´í„°ë¡œ ì˜ìƒ ìƒì„± ìš”ì²­
  const handleSidebarSubmit = async (data: VideoGenerationData) => {
    console.log(`ğŸ¯ [ë¹„ë””ì˜¤ ìƒì„±] handleSidebarSubmit ì‹œì‘:`, {
      endpoint: data.endpoint,
      activeTab,
      hasImageFile: !!data.imageFile,
      hasFileUrl: !!data.fileUrl,
      prompt: data.prompt?.substring(0, 50) + '...',
      userId: userId?.toString() || 'none'
    });

    setErrorMessage("");
    setVideoUrl("");
    setUpscaledVideoUrl("");

    try {
      if (!userId) {
        toast({
          title: "ì˜¤ë¥˜",
          description: "ì‚¬ìš©ì ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.",
          variant: "destructive",
        });
        router.push("/login");
        return;
      }

      // ì˜ìƒ ìƒì„±ìš© ì›¹ì†Œì¼“ ì—°ê²°
      await connectForVideoGeneration();
      console.log('ğŸ”— [ë¹„ë””ì˜¤ ìƒì„±] ì›¹ì†Œì¼“ ì—°ê²° ì™„ë£Œ');

      // í˜„ì¬ í¬ë ˆë”§ í™•ì¸
      const creditResponse = await BillingService.getCurrentCredit();
      if (creditResponse.currentCredit < 10) {
        toast({
          title: "í¬ë ˆë”§ ë¶€ì¡±",
          description: "í¬ë ˆë”§ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. í¬ë ˆë”§ì„ ì¶©ì „í•´ì£¼ì„¸ìš”.",
          variant: "destructive",
        });
        router.push("/payment");
        return;
      }

      // í¬ë ˆë”§ ì†Œë¹„ ìš”ì²­: UI ì¦‰ì‹œ ë°˜ì˜
      updateCredits(-10);
      try {
        await BillingService.consumeCredit({
          amount: 10,
          reason: "ë¹„ë””ì˜¤ ìƒì„±"
        });
      } catch (err) {
        // ì‹¤íŒ¨ì‹œ ë¡¤ë°±
        updateCredits(10);
        throw err;
      }

      // ì´ë¯¸ì§€ ì²˜ë¦¬
      let imageBase64 = "";
      if (data.imageFile) {
        try {
          imageBase64 = await readFileAsBase64(data.imageFile);
        } catch (error) {
          console.error("Error reading file as Base64:", error);
          toast({
            title: "ì˜¤ë¥˜",
            description: "ì´ë¯¸ì§€ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            variant: "destructive",
          });
          return;
        }
      }

      // ì´ë¯¸ì§€ URL ê²€ì¦
      const imageUrl = imageBase64 || data.fileUrl || '';
      
      if (!imageUrl) {
        console.error(`âŒ [ë¹„ë””ì˜¤ ìƒì„±] ${data.endpoint} API í˜¸ì¶œ ë¶ˆê°€: ì´ë¯¸ì§€ URLì´ ì—†ìŠµë‹ˆë‹¤.`);
        toast({
          title: "ì˜¤ë¥˜",
          description: "ì´ë¯¸ì§€ ì •ë³´ê°€ ì—†ì–´ ë¹„ë””ì˜¤ ìƒì„±ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
          variant: "destructive",
        });
        return;
      }

      // ğŸ¯ Spring Bootì— ì•Œë¦¼ì„ ë¨¼ì € ìƒì„±í•˜ê³  notificationId ë°›ê¸°
      let notificationId = '';
      try {
        const notification = await GenerationNotificationService.createNotification({
          title: `${data.endpoint} ëª¨ë¸ë¡œ ì˜ìƒ ìƒì„± ì¤‘`,
          thumbnailUrl: imageUrl.startsWith('data:') ? '' : imageUrl,
          mediaCount: 1,
        });
        notificationId = notification.id.toString();
        console.log(`âœ… [ì•Œë¦¼ ìƒì„±] Spring Boot ì•Œë¦¼ ìƒì„± ì™„ë£Œ - ID: ${notificationId}`);
        
        // ì•Œë¦¼ ìƒì„±ë¨ì„ ì•Œë¦¬ëŠ” ì´ë²¤íŠ¸ ë°œìƒ
        window.dispatchEvent(new CustomEvent('open-notification-bell'));
      } catch (notificationError) {
        console.error("âŒ [ì•Œë¦¼ ìƒì„±] Spring Boot ì•Œë¦¼ ìƒì„± ì‹¤íŒ¨:", notificationError);
        toast({
          title: "ì˜¤ë¥˜", 
          description: "ì•Œë¦¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜ìƒ ìƒì„±ì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.",
          variant: "destructive",
        });
        // ì•Œë¦¼ ìƒì„± ì‹¤íŒ¨í•´ë„ ì˜ìƒ ìƒì„±ì€ ê³„ì† ì§„í–‰
      }

      console.log(`ğŸš€ [ë¹„ë””ì˜¤ ìƒì„±] VideoApiService ìš”ì²­ ì „ì†¡ ì¤‘:`, {
        endpoint: data.endpoint,
        userId: userId?.toString() || 'none',
        notificationId: notificationId || 'none',
        hasImageUrl: !!imageUrl,
        imageUrlLength: imageUrl.length,
        prompt: data.prompt?.substring(0, 50) + '...',
        seed: data.seed,
        duration: data.duration,
        aspectRatio: data.aspectRatio
      });

      // VideoApiServiceë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ë³„ ìš”ì²­
      let result;
      
      switch (data.endpoint) {
        case "hunyuan":
          result = await VideoApiService.createHunyuanVideo({
            userId: userId.toString(),
            prompt: data.prompt,
            imageUrl,
            notificationId: notificationId,
            seed: data.seed,
            aspect_ratio: data.aspectRatio as AspectRatioType,
            resolution: data.resolution as ResolutionType,
            num_frames: data.numFrames,
            i2v_stability: true,
          });
          break;
          
        case "kling":
          result = await VideoApiService.createKlingVideo({
            userId: userId.toString(),
            prompt: data.prompt,
            imageUrl,
            notificationId: notificationId,
            seed: data.seed,
            duration: data.duration as "5s" | "10s",
            negative_prompt: data.negative_prompt || "blur, distort, and low quality",
            cfg_scale: data.cfg_scale || 0.5,
          });
          break;
          
        case "veo2":
          result = await VideoApiService.createVeo2Video({
            userId: userId.toString(),
            prompt: data.prompt,
            imageUrl,
            notificationId: notificationId,
            seed: data.seed,
            aspect_ratio: data.aspectRatio as AspectRatioType,
            duration: data.duration as DurationType,
          });
          break;
          
        case "pixverse":
          const pixverseDuration = data.duration.replace('s', '') as "5" | "8";
          result = await VideoApiService.createPixverseVideo({
            userId: userId.toString(),
            prompt: data.prompt,
            imageUrl,
            notificationId: notificationId,
            seed: data.seed,
            aspect_ratio: data.aspectRatio as AspectRatioType,
            resolution: data.resolution as ResolutionType,
            duration: pixverseDuration,
            negative_prompt: data.negative_prompt,
            style: data.style as "anime" | "3d_animation" | "clay" | "comic" | "cyberpunk",
          });
          break;
          
        case "wan":
          result = await VideoApiService.createWanVideo({
            userId: userId.toString(),
            prompt: data.prompt,
            imageUrl,
            notificationId: notificationId,
            seed: data.seed || Math.floor(Math.random() * 1000000),
            enableSafetyChecker: true,
          });
          break;
          
        default:
          throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: ${data.endpoint}`);
      }

      // ì‘ë‹µ ì²˜ë¦¬ (ì‘ì—… ID ê¸°ë°˜)
      console.log(`âœ… [ë¹„ë””ì˜¤ ìƒì„±] VideoApiService ì‘ë‹µ:`, result);
      
      if (result && result.jobId) {
        // ì„±ê³µì ìœ¼ë¡œ ì‘ì—…ì´ ì‹œì‘ë¨
        toast({
          title: "ì˜ìƒ ìƒì„± ì‹œì‘",
          description: `ë¹„ë””ì˜¤ ìƒì„± ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‘ì—… ID: ${result.jobId}`,
        });
        
        console.log(`âœ… [ë¹„ë””ì˜¤ ìƒì„±] ì‘ì—… ì‹œì‘ë¨ - ëª¨ë¸: ${data.endpoint}, ì‘ì—… ID: ${result.jobId}, ì•Œë¦¼ ID: ${notificationId}`);
        
        // WebSocketì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì™„ë£Œ ì•Œë¦¼ì„ ë°›ì„ ì˜ˆì •
        toast({
          title: "ì§„í–‰ ì¤‘",
          description: "ì˜ìƒ ìƒì„± ìš”ì²­ì´ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì™„ë£Œë˜ë©´ ì•Œë¦¼ì„ ë°›ê²Œ ë©ë‹ˆë‹¤.",
        });
      } else {
        throw new Error('ì‘ì—… IDë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
      }

    } catch (error: unknown) {
      console.error("ë¹„ë””ì˜¤ ìƒì„± ì „ì²´ í”Œë¡œìš° ì˜¤ë¥˜:", error);
      const errorMessage = error instanceof Error ? error.message : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ";
      setErrorMessage(errorMessage);
      toast({
        title: "ì˜¤ë¥˜",
        description: `ì˜ìƒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: ${errorMessage}`,
        variant: "destructive",
      });
    }
  };

  // ì—…ìŠ¤ì¼€ì¼ë§ ì²˜ë¦¬ í•¨ìˆ˜
  const handleUpscaleVideo = async () => {
    if (!videoUrl) return;

    try {
      setIsUpscaling(true);

      const response = await fetch('/internal/video/upscaler', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ videoUrl }),
      });

      if (!response.ok) {
        throw new Error(`ì—…ìŠ¤ì¼€ì¼ë§ ìš”ì²­ ì‹¤íŒ¨: ${response.status}`);
      }

      const result = await response.json();

      if (result.data?.video_upscaled) {
        setUpscaledVideoUrl(result.data.video_upscaled);
        toast({
          title: "ì™„ë£Œ",
          description: "ë¹„ë””ì˜¤ ì—…ìŠ¤ì¼€ì¼ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
        });
      } else {
        throw new Error("ì—…ìŠ¤ì¼€ì¼ë§ëœ ë¹„ë””ì˜¤ URLì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤");
      }
    } catch (error) {
      console.error("ì—…ìŠ¤ì¼€ì¼ë§ ì˜¤ë¥˜:", error);
      toast({
        title: "ì˜¤ë¥˜",
        description: error instanceof Error ? error.message : "ì—…ìŠ¤ì¼€ì¼ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
        variant: "destructive",
      });
    } finally {
      setIsUpscaling(false);
    }
  };

  const handleTabChange = (tab: "video" | "image" | "text") => {
    if (tab === "image" || tab === "text") {
      setActiveTab(tab);
    }
  };

  const handleAddReferenceImage = async (fileItem: FileItem) => {
    setReferenceImageUrl(fileItem.fileUrl);
  };

  const handleImageChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      setReferenceImageFile(file);
      setReferenceImageUrl(URL.createObjectURL(file));
    }
  };

  const selectImage = () => {
    document.getElementById("imageInput")?.click();
  };

  const removeImage = () => {
    setReferenceImageFile(null);
    setReferenceImageUrl("");
  };

  // Base64 ë³€í™˜ í•¨ìˆ˜
  const readFileAsBase64 = (file: File): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        if (typeof reader.result === 'string') {
          resolve(reader.result);
        } else {
          reject(new Error('Failed to convert file to Base64'));
        }
      };
      reader.onerror = () => {
        reject(reader.error);
      };
      reader.readAsDataURL(file);
    });
  };

  return {
    videoUrl,
    errorMessage,
    isUpscaling,
    upscaledVideoUrl,
    activeTab,
    selectedEndpoint,
    quality,
    style,
    referenceImageFile,
    referenceImageUrl,
    referencePrompt,
    referenceModel,
    isConnected,
    handleSidebarSubmit,
    handleUpscaleVideo,
    handleTabChange,
    handleAddReferenceImage,
    handleImageChange,
    selectImage,
    removeImage,
    setSelectedEndpoint,
    setQuality,
    setStyle,
    setReferencePrompt
  };
} 